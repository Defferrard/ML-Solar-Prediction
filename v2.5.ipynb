{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[SKLearn GaussianProcessRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html)\n",
    "\n",
    "# TODO\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "from tester import Algorithm, Tester\n",
    "T = Tester()\n",
    "algos = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7749134348319178"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "class CustomHGBR(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        return x\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = HistGradientBoostingRegressor(learning_rate=0.075, max_depth=3, max_iter=55, max_leaf_nodes=8, min_samples_leaf=5, quantile=0.1)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algos.append(('HistGradientBoostingRegressor', CustomHGBR()))\n",
    "algo = CustomHGBR()\n",
    "[y_pred_tot, y_true_tot] = T.evaluate(algo, debug=False, use_thread=True)\n",
    "r2_score(y_true_tot, y_pred_tot)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "class CustomMLP(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        x = x.fillna(method='ffill')\n",
    "        return x\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = MLPRegressor(\n",
    "            hidden_layer_sizes=(350, 350, 350),\n",
    "            activation='tanh',\n",
    "            solver='adam',\n",
    "            alpha=1e-5,\n",
    "            learning_rate_init=0.001,\n",
    "            max_iter=500\n",
    "        )\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algo = CustomMLP()\n",
    "#[y_pred_tot, y_true_tot] = T.evaluate(algo, debug=False)\n",
    "#r2_score(y_true_tot, y_pred_tot)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "class CustomGPR(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        x = x.fillna(method='ffill')\n",
    "        return x\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = GaussianProcessRegressor()\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algo = CustomGPR()\n",
    "#[y_pred_tot, y_true_tot] = T.evaluate(algo, debug=False)\n",
    "#r2_score(y_true_tot, y_pred_tot)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "class CustomGBR(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        x = x.fillna(method='ffill')\n",
    "        return x\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = GradientBoostingRegressor()\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algos.append(('GradientBoostingRegressor with ffill', CustomGBR()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "class CustomRFG(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        imp = SimpleImputer(strategy='mean')\n",
    "        imp.fit(x)\n",
    "        return pd.DataFrame(imp.transform(x), columns=x.columns)\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algos.append(('RandomForestRegressor with ffill', CustomRFG()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "class CustomRCV(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        x = x.fillna(method='ffill')\n",
    "        return x\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = RidgeCV()\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algos.append(('RidgeCV with ffill', CustomRCV()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "class CustomLR(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        x = x.fillna(method='ffill')\n",
    "        return x\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = LinearRegression()\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algos.append(('LinearRegression with ffill', CustomLR()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "class CustomKNR(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        x = x.fillna(method='ffill')\n",
    "        scaler.fit(x)\n",
    "        x = pd.DataFrame(scaler.transform(x), columns=x.columns)\n",
    "        return x\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = KNeighborsRegressor()\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algos.append(('KNeighborsRegressor with ffill and MinMaxScaler', CustomKNR()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "class CustomDTR(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        x = x.fillna(method='ffill')\n",
    "        scaler.fit(x)\n",
    "        x = pd.DataFrame(scaler.transform(x), columns=x.columns)\n",
    "        return x\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = DecisionTreeRegressor()\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algos.append(('DecisionTreeRegressor with ffill and MinMaxScaler', CustomDTR()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "class CustomXGBR(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        x = x.fillna(method='ffill')\n",
    "        scaler.fit(x)\n",
    "        x = pd.DataFrame(scaler.transform(x), columns=x.columns)\n",
    "        return x\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = XGBRegressor()\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algos.append(('XGBRegressor with ffill and MinMaxScaler', CustomXGBR()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "class CustomSR(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        x = x.fillna(method='ffill')\n",
    "        return x\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        base_models = [('hgbr',HistGradientBoostingRegressor()), ('gbr',GradientBoostingRegressor()), ('rfr',RandomForestRegressor()), ('xgbr',XGBRegressor())]\n",
    "        model = StackingRegressor(estimators=base_models)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algos.append(('StackingRegressor with ffill, HistGradientBoostingRegressor, GradientBoostingRegressor, RandomForestRegressor, XGBRegressor', CustomSR()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "class CustomGBRMean(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        imp = SimpleImputer(strategy='mean')\n",
    "        imp.fit(x)\n",
    "        return pd.DataFrame(imp.transform(x), columns=x.columns)\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = GradientBoostingRegressor()\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algos.append(('GradientBoostingRegressor with SimpleImputer strategy: mean', CustomGBRMean()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "class CustomGBRMedian(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        imp = SimpleImputer(strategy='median')\n",
    "        imp.fit(x)\n",
    "        return pd.DataFrame(imp.transform(x), columns=x.columns)\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = GradientBoostingRegressor()\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algos.append(('GradientBoostingRegressor with SimpleImputer strategy: median', CustomGBRMedian()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "class CustomGBRFrequent(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        imp = SimpleImputer(strategy='most_frequent')\n",
    "        imp.fit(x)\n",
    "        return pd.DataFrame(imp.transform(x), columns=x.columns)\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = GradientBoostingRegressor()\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algos.append(('GradientBoostingRegressor with SimpleImputer strategy: most frequent', CustomGBRFrequent()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "class CustomGBR0(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        imp = SimpleImputer(strategy='constant', fill_value=0 )\n",
    "        imp.fit(x)\n",
    "        return pd.DataFrame(imp.transform(x), columns=x.columns)\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = GradientBoostingRegressor()\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algos.append(('GradientBoostingRegressor with SimpleImputer strategy: constant 0', CustomGBR0()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "class CustomGBRIterative(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x = super().format_x(x)\n",
    "        x = x.drop(['Unnamed: 0', 'Date' ,'snow', 'snowdepth', 'winddir', 'conditions'], axis=1)\n",
    "        imp = IterativeImputer(max_iter = 100)\n",
    "        imp.fit(x)\n",
    "        return pd.DataFrame(imp.transform(x), columns=x.columns)\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = GradientBoostingRegressor()\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "algos.append(('GradientBoostingRegressor with IterativeImputer', CustomGBRIterative()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    0             1\n0                       HistGradientBoostingRegressor      0.778334\n1                GradientBoostingRegressor with ffill      0.773639\n2                    RandomForestRegressor with ffill      0.741750\n3                                  RidgeCV with ffill -25523.560692\n4                         LinearRegression with ffill      0.116295\n5     KNeighborsRegressor with ffill and MinMaxScaler      0.387941\n6   DecisionTreeRegressor with ffill and MinMaxScaler      0.655490\n7            XGBRegressor with ffill and MinMaxScaler      0.745511\n8   StackingRegressor with ffill, HistGradientBoos...      0.779257\n9   GradientBoostingRegressor with SimpleImputer s...      0.769744\n10  GradientBoostingRegressor with SimpleImputer s...      0.745014\n11  GradientBoostingRegressor with SimpleImputer s...      0.749263\n12  GradientBoostingRegressor with SimpleImputer s...      0.761214\n13    GradientBoostingRegressor with IterativeImputer      0.760489",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HistGradientBoostingRegressor</td>\n      <td>0.778334</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GradientBoostingRegressor with ffill</td>\n      <td>0.773639</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RandomForestRegressor with ffill</td>\n      <td>0.741750</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RidgeCV with ffill</td>\n      <td>-25523.560692</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LinearRegression with ffill</td>\n      <td>0.116295</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KNeighborsRegressor with ffill and MinMaxScaler</td>\n      <td>0.387941</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>DecisionTreeRegressor with ffill and MinMaxScaler</td>\n      <td>0.655490</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>XGBRegressor with ffill and MinMaxScaler</td>\n      <td>0.745511</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>StackingRegressor with ffill, HistGradientBoos...</td>\n      <td>0.779257</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>GradientBoostingRegressor with SimpleImputer s...</td>\n      <td>0.769744</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>GradientBoostingRegressor with SimpleImputer s...</td>\n      <td>0.745014</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>GradientBoostingRegressor with SimpleImputer s...</td>\n      <td>0.749263</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>GradientBoostingRegressor with SimpleImputer s...</td>\n      <td>0.761214</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>GradientBoostingRegressor with IterativeImputer</td>\n      <td>0.760489</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for name, algo in algos:\n",
    "    [y_pred_tot, y_true_tot] = T.evaluate(algo, debug=False, use_thread=True)\n",
    "    r2_score(y_true_tot, y_pred_tot)\n",
    "    res.append((name, r2_score(y_true_tot, y_pred_tot)))\n",
    "res = pd.DataFrame(res)\n",
    "res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 0 start !\n",
      "K: 1 start !\n",
      "K: 2 start !\n",
      "K: 3 start !\n",
      "K: 4 start !\n",
      "K: 5 start !\n",
      "K: 6 start !\n",
      "K: 7 start !\n",
      "K: 8 start !\n",
      "K: 9 start !\n",
      "K: 10 start !\n",
      "K: 11 start !\n",
      "K: 12 start !\n",
      "K: 13 start !\n",
      "K: 14 start !\n",
      "K: 15 start !\n",
      "K: 16 start !\n",
      "K: 17 start !\n",
      "K: 18 start !\n",
      "K: 19 start !\n",
      "K: 20 start !\n",
      "K: 21 start !\n",
      "K: 22 start !\n",
      "K: 23 start !\n",
      "K: 24 start !\n",
      "K: 25 start !\n",
      "K: 26 start !\n",
      "K: 27 start !\n",
      "K: 28 start !\n",
      "K: 29 start !\n",
      "K: 30 start !\n",
      "K: 31 start !\n",
      "K: 32 start !\n",
      "K: 33 start !\n",
      "K: 34 start !\n",
      "K: 35 start !\n",
      "K: 36 start !\n",
      "K: 37 start !\n",
      "K: 38 start !\n",
      "K: 39 start !\n",
      "K: 40 start !\n",
      "K: 41 start !\n",
      "K: 42 start !\n",
      "K: 43 start !\n",
      "K: 44 start !\n",
      "K: 45 start !\n",
      "K: 46 start !\n",
      "K: 47 start !\n",
      "K: 48 start !\n",
      "K: 49 start !\n",
      "Waiting for thread 0 results...\n",
      "Thread: 2 done !\n",
      "Thread: 6 done !\n",
      "Thread: 5 done !\n",
      "Thread: 49 done !\n",
      "Thread: 14 done !\n",
      "Thread: 18 done !\n",
      "Thread: 1 done !\n",
      "Thread: 22 done !\n",
      "Thread: 4 done !\n",
      "Thread: 20 done !\n",
      "Thread: 8 done !\n",
      "Thread: 26 done !\n",
      "Thread: 12 done !\n",
      "Thread: 10 done !\n",
      "Thread: 13 done !\n",
      "Thread: 17 done !\n",
      "Thread: 27 done !\n",
      "Thread: 31 done !\n",
      "Thread: 16 done !\n",
      "Thread: 48 done !\n",
      "Thread: 15 done !\n",
      "Thread: 24 done !\n",
      "Thread: 35 done !\n",
      "Thread: 32 done !\n",
      "Thread: 3 done !\n",
      "Thread: 19 done !\n",
      "Thread: 39 done !\n",
      "Thread: 9 done !\n",
      "Thread: 40 done !\n",
      "Thread: 23 done !\n",
      "Thread: 36 done !\n",
      "Thread: 11 done !\n",
      "Thread: 44 done !\n",
      "Thread: 28 done !\n",
      "Thread: 46 done !\n",
      "Thread: 43 done !\n",
      "Thread: 47 done !\n",
      "Thread: 38 done !\n",
      "Thread: 7 done !\n",
      "Thread: 42 done !\n",
      "Thread: 33 done !\n",
      "Thread: 29 done !\n",
      "Thread: 34 done !\n",
      "Thread: 25 done !\n",
      "Thread: 0 done !\n",
      "Get thread 0 results...\n",
      "Waiting for thread 1 results...\n",
      "Get thread 1 results...\n",
      "Waiting for thread 2 results...\n",
      "Get thread 2 results...\n",
      "Waiting for thread 3 results...\n",
      "Get thread 3 results...\n",
      "Waiting for thread 4 results...\n",
      "Get thread 4 results...\n",
      "Waiting for thread 5 results...\n",
      "Get thread 5 results...\n",
      "Waiting for thread 6 results...\n",
      "Get thread 6 results...\n",
      "Waiting for thread 7 results...\n",
      "Get thread 7 results...\n",
      "Waiting for thread 8 results...\n",
      "Get thread 8 results...\n",
      "Waiting for thread 9 results...\n",
      "Get thread 9 results...\n",
      "Waiting for thread 10 results...\n",
      "Get thread 10 results...\n",
      "Thread: 41 done !\n",
      "Waiting for thread 11 results...\n",
      "Get thread 11 results...\n",
      "Waiting for thread 12 results...\n",
      "Get thread 12 results...\n",
      "Waiting for thread 13 results...\n",
      "Get thread 13 results...\n",
      "Waiting for thread 14 results...\n",
      "Get thread 14 results...\n",
      "Waiting for thread 15 results...\n",
      "Get thread 15 results...\n",
      "Waiting for thread 16 results...\n",
      "Get thread 16 results...\n",
      "Waiting for thread 17 results...\n",
      "Get thread 17 results...\n",
      "Waiting for thread 18 results...\n",
      "Get thread 18 results...\n",
      "Waiting for thread 19 results...\n",
      "Get thread 19 results...\n",
      "Waiting for thread 20 results...\n",
      "Get thread 20 results...\n",
      "Waiting for thread 21 results...\n",
      "Thread: 37 done !\n",
      "Thread: 21 done !\n",
      "Get thread 21 results...\n",
      "Waiting for thread 22 results...\n",
      "Get thread 22 results...\n",
      "Waiting for thread 23 results...\n",
      "Get thread 23 results...\n",
      "Waiting for thread 24 results...\n",
      "Get thread 24 results...\n",
      "Waiting for thread 25 results...\n",
      "Get thread 25 results...\n",
      "Waiting for thread 26 results...\n",
      "Get thread 26 results...\n",
      "Waiting for thread 27 results...\n",
      "Get thread 27 results...\n",
      "Waiting for thread 28 results...\n",
      "Get thread 28 results...\n",
      "Thread: 45 done !\n",
      "Waiting for thread 29 results...\n",
      "Get thread 29 results...\n",
      "Waiting for thread 30 results...\n",
      "Thread: 30 done !\n",
      "Get thread 30 results...\n",
      "Waiting for thread 31 results...\n",
      "Get thread 31 results...\n",
      "Waiting for thread 32 results...\n",
      "Get thread 32 results...\n",
      "Waiting for thread 33 results...\n",
      "Get thread 33 results...\n",
      "Waiting for thread 34 results...\n",
      "Get thread 34 results...\n",
      "Waiting for thread 35 results...\n",
      "Get thread 35 results...\n",
      "Waiting for thread 36 results...\n",
      "Get thread 36 results...\n",
      "Waiting for thread 37 results...\n",
      "Get thread 37 results...\n",
      "Waiting for thread 38 results...\n",
      "Get thread 38 results...\n",
      "Waiting for thread 39 results...\n",
      "Get thread 39 results...\n",
      "Waiting for thread 40 results...\n",
      "Get thread 40 results...\n",
      "Waiting for thread 41 results...\n",
      "Get thread 41 results...\n",
      "Waiting for thread 42 results...\n",
      "Get thread 42 results...\n",
      "Waiting for thread 43 results...\n",
      "Get thread 43 results...\n",
      "Waiting for thread 44 results...\n",
      "Get thread 44 results...\n",
      "Waiting for thread 45 results...\n",
      "Get thread 45 results...\n",
      "Waiting for thread 46 results...\n",
      "Get thread 46 results...\n",
      "Waiting for thread 47 results...\n",
      "Get thread 47 results...\n",
      "Waiting for thread 48 results...\n",
      "Get thread 48 results...\n",
      "Waiting for thread 49 results...\n",
      "Get thread 49 results...\n",
      "Done getting results !\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8362029851558667"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import suncalc\n",
    "\n",
    "from tester import Algorithm, Tester\n",
    "T = Tester()\n",
    "\n",
    "\n",
    "class CustomBetterGBR(Algorithm):\n",
    "    def format_x(self, x:pd.DataFrame) -> pd.DataFrame:\n",
    "        x['Date'] = pd.to_datetime(x['Date'])\n",
    "        x.sort_values(by='Date', ascending=True)\n",
    "        x['Date'] = x['Date'] - pd.Timedelta(hours=2)\n",
    "        x['timestamp'] = x['Date'].apply(lambda x: int(x.timestamp()))\n",
    "        x['day'] = x['Date'].dt.day\n",
    "        x['month'] = x['Date'].dt.month\n",
    "        x['hour'] = x['Date'].dt.hour\n",
    "        x['minute'] = x['Date'].dt.minute\n",
    "        x['timeofday'] = x['minute'] + x['hour'] * 60\n",
    "        x['timeofyear'] = (x['Date'].dt.dayofyear * 24 + x['hour']) * 60 + x['minute']\n",
    "\n",
    "        latitude = 46.5095\n",
    "        longitude = 6.6243\n",
    "\n",
    "        sun_pos = pd.DataFrame.from_dict(\n",
    "        x['Date'].apply(lambda d: suncalc.get_position(d.to_pydatetime(), longitude, latitude)).to_dict(), orient='index')\n",
    "        sun_time = pd.DataFrame.from_dict(\n",
    "        x['Date'].apply(lambda d: suncalc.get_times(d.to_pydatetime(), longitude, latitude)).to_dict(), orient='index')\n",
    "        sun_time = sun_time.applymap(pd.to_datetime)\n",
    "        sun_time = sun_time.apply(lambda x: x.dt.second + x.dt.minute * 60 + x.dt.hour * 3600)\n",
    "        sun_time = sun_time.subtract(x['timeofday'], axis=0)\n",
    "        x = pd.concat([x, sun_pos, sun_time], axis=1)\n",
    "\n",
    "        x = x.drop(['Unnamed: 0', 'Date', 'conditions'], axis=1)\n",
    "\n",
    "        # Create a boolean mask that is true for rows where column A is not NaN\n",
    "        mask = x['temp'].notna()\n",
    "\n",
    "        # Use the mask to select the rows where column A is not NaN and column B has NaN\n",
    "        x.loc[mask & x['uvindex'].isna(), 'uvindex'] = 0\n",
    "        x.loc[mask & x['solarenergy'].isna(), 'solarenergy'] = 0\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(x)\n",
    "        x = pd.DataFrame(scaler.transform(x), columns=x.columns)\n",
    "\n",
    "        imp = KNNImputer(n_neighbors=3, weights=\"distance\")\n",
    "        x = pd.DataFrame(imp.fit_transform(x), columns=x.columns)\n",
    "\n",
    "        c1 = -42.379\n",
    "        c2 = 2.04901523\n",
    "        c3 = 10.14333127\n",
    "        c4 = -0.22475541\n",
    "        c5 = -6.83783e-03\n",
    "        c6 = -5.481717e-02\n",
    "        c7 = 1.22874e-03\n",
    "        c8 = 8.5282e-04\n",
    "        c9 = -1.99e-06\n",
    "        x['heat_index'] = c1 + c2 * x['temp'] + c3 * x['humidity'] + c4 * x['temp'] * x['humidity'] + c5 * x[\n",
    "            'temp'] ** 2 + c6 * x['humidity'] ** 2 + c7 * x['temp'] ** 2 * x['humidity'] + c8 * x['temp'] * x[\n",
    "                              'humidity'] ** 2 + c9 * x['temp'] ** 2 * x['humidity'] ** 2\n",
    "\n",
    "        x = x.drop(['snow', 'snowdepth', 'winddir', 'minute', 'hour', 'month',  'visibility', 'windspeed', 'solarradiation'], axis=1)\n",
    "\n",
    "        x = x.drop(sun_time.columns, axis=1)\n",
    "        x = x.drop(sun_pos.columns, axis=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def algo(self, x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame) -> pd.DataFrame:\n",
    "        model = GradientBoostingRegressor(tol=1e-10,\n",
    "                                          loss= 'huber',\n",
    "                                          learning_rate= 0.05316331095322675,\n",
    "                                          n_estimators= 76,\n",
    "                                          subsample= 0.11735357563724402,\n",
    "                                          criterion= 'friedman_mse',\n",
    "                                          min_samples_split= 42,\n",
    "                                          min_samples_leaf= 45,\n",
    "                                          max_depth= 5,\n",
    "                                          min_impurity_decrease= 0.3853769497148342,\n",
    "                                          max_leaf_nodes= 10,\n",
    "                                          random_state= 42)\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_pred[y_pred < 0] = 0\n",
    "        return y_pred\n",
    "\n",
    "'''\n",
    "tol=1e-10,\n",
    "loss= 'huber',\n",
    "learning_rate= 0.0535038718924189,\n",
    "n_estimators= 65,\n",
    "subsample= 0.22459569628555273,\n",
    "criterion= 'friedman_mse',\n",
    "min_samples_split= 39,\n",
    "min_samples_leaf= 49,\n",
    "max_depth= 9,\n",
    "min_impurity_decrease= 0.4333439547159551,\n",
    "max_leaf_nodes= 10,\n",
    "7914026845188614\n",
    "\n",
    "\n",
    "tol=1e-10,\n",
    "loss= 'huber',\n",
    "learning_rate= 0.05316331095322675,\n",
    "n_estimators= 76,\n",
    "subsample= 0.11735357563724402,\n",
    "criterion= 'friedman_mse',\n",
    "min_samples_split= 42,\n",
    "min_samples_leaf= 45,\n",
    "max_depth= 5,\n",
    "min_impurity_decrease= 0.3853769497148342,\n",
    "max_leaf_nodes= 10,\n",
    "7986403800256977\n",
    "}\n",
    "\n",
    "'''\n",
    "\n",
    "algo = CustomBetterGBR()\n",
    "[y_pred_tot, y_true_tot] = T.evaluate(algo, k=50, debug=True, use_thread=True)\n",
    "r2_score(y_true_tot, y_pred_tot)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "        id  predicted\n0        0   0.132109\n1        1   0.132109\n2        2   0.132109\n3        3   0.132109\n4        4   0.132109\n...    ...        ...\n2299  2299   0.013937\n2300  2300   0.013937\n2301  2301   0.013937\n2302  2302   0.013937\n2303  2303   0.013937\n\n[2304 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.132109</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.132109</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.132109</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.132109</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.132109</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2299</th>\n      <td>2299</td>\n      <td>0.013937</td>\n    </tr>\n    <tr>\n      <th>2300</th>\n      <td>2300</td>\n      <td>0.013937</td>\n    </tr>\n    <tr>\n      <th>2301</th>\n      <td>2301</td>\n      <td>0.013937</td>\n    </tr>\n    <tr>\n      <th>2302</th>\n      <td>2302</td>\n      <td>0.013937</td>\n    </tr>\n    <tr>\n      <th>2303</th>\n      <td>2303</td>\n      <td>0.013937</td>\n    </tr>\n  </tbody>\n</table>\n<p>2304 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.generate_result(algo, csv_name=\"temp.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nx['heat_index'] = c1 + c2*x['temp'] + c3*x['humidity'] + c4*x['temp']*x['humidity'] + c5*x['temp']**2 + c6*x['humidity']**2 + c7*x['temp']**2*x['humidity'] + c8*x['temp']*x['humidity']**2 + c9*x['temp']**2*x['humidity']**2\\nx['rad_temp_ratio'] = x['solarradiation']/x['temp']\\n\\nx['windspeedx'] = np.cos(np.deg2rad(x['winddir'])) * x['windspeed']\\nx['windspeedy'] = np.sin(np.deg2rad(x['winddir'])) * x['windspeed']\\n\\nsun_pos = pd.DataFrame.from_dict(x['Date'].apply(lambda d: suncalc.get_position(d.to_pydatetime(), longitude, latitude)).to_dict() , orient='index')\\nx = pd.concat([x, sun_pos], axis=1)\\n\""
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "x['heat_index'] = c1 + c2*x['temp'] + c3*x['humidity'] + c4*x['temp']*x['humidity'] + c5*x['temp']**2 + c6*x['humidity']**2 + c7*x['temp']**2*x['humidity'] + c8*x['temp']*x['humidity']**2 + c9*x['temp']**2*x['humidity']**2\n",
    "x['rad_temp_ratio'] = x['solarradiation']/x['temp']\n",
    "\n",
    "x['windspeedx'] = np.cos(np.deg2rad(x['winddir'])) * x['windspeed']\n",
    "x['windspeedy'] = np.sin(np.deg2rad(x['winddir'])) * x['windspeed']\n",
    "\n",
    "sun_pos = pd.DataFrame.from_dict(x['Date'].apply(lambda d: suncalc.get_position(d.to_pydatetime(), longitude, latitude)).to_dict() , orient='index')\n",
    "x = pd.concat([x, sun_pos], axis=1)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                        date     lon      lat     d   azimuth  altitude  \\\n0 2023-01-14 22:18:31.161792  6.6243  46.5095  1338  2.065323 -0.897162   \n\n   solar_noon  nadir  sunrise  sunset  sunrise_end  sunset_start   dawn  \\\n0      -38072   5128   -54166  -21978       -53949        -22196 -56206   \n\n    dusk  nautical_dawn  nautical_dusk  night_end  night  golden_hour_end  \\\n0 -19938         -58459         -17685     -60631 -15514           -51239   \n\n   golden_hour  \n0       -24906  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>lon</th>\n      <th>lat</th>\n      <th>d</th>\n      <th>azimuth</th>\n      <th>altitude</th>\n      <th>solar_noon</th>\n      <th>nadir</th>\n      <th>sunrise</th>\n      <th>sunset</th>\n      <th>sunrise_end</th>\n      <th>sunset_start</th>\n      <th>dawn</th>\n      <th>dusk</th>\n      <th>nautical_dawn</th>\n      <th>nautical_dusk</th>\n      <th>night_end</th>\n      <th>night</th>\n      <th>golden_hour_end</th>\n      <th>golden_hour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-01-14 22:18:31.161792</td>\n      <td>6.6243</td>\n      <td>46.5095</td>\n      <td>1338</td>\n      <td>2.065323</td>\n      <td>-0.897162</td>\n      <td>-38072</td>\n      <td>5128</td>\n      <td>-54166</td>\n      <td>-21978</td>\n      <td>-53949</td>\n      <td>-22196</td>\n      <td>-56206</td>\n      <td>-19938</td>\n      <td>-58459</td>\n      <td>-17685</td>\n      <td>-60631</td>\n      <td>-15514</td>\n      <td>-51239</td>\n      <td>-24906</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import suncalc\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tester import Algorithm, Tester\n",
    "T = Tester()\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "latitude = 46.5095\n",
    "longitude = 6.6243\n",
    "df = pd.DataFrame({\n",
    "    'date': [datetime.now()] * 1,\n",
    "    'lon': [longitude] * 1,\n",
    "    'lat': [latitude] * 1\n",
    "})\n",
    "sun_pos = pd.DataFrame.from_dict(df['date'].apply(lambda d: suncalc.get_position(d.to_pydatetime(), longitude, latitude)).to_dict() , orient='index')\n",
    "sun_time = pd.DataFrame.from_dict(df['date'].apply(lambda d: suncalc.get_times(d.to_pydatetime(), longitude, latitude)).to_dict() , orient='index')\n",
    "\n",
    "\n",
    "sun_time = sun_time.apply(pd.to_datetime, infer_datetime_format=True)\n",
    "sun_time = sun_time.apply(lambda x: x.dt.second + x.dt.minute * 60 + x.dt.hour * 3600)\n",
    "\n",
    "df['d'] = df['date'].dt.minute + df['date'].dt.hour * 60\n",
    "df = pd.concat([df, sun_pos, sun_time], axis=1)\n",
    "for col in sun_time.columns:\n",
    "    df[col] = df[col] - df['d'] *60\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
